<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Nils Kuhn</title>
    <meta name="description" content="Webpage of Nils Kuhn — Robotics, AI, and Machine Learning." />
    <link rel="stylesheet" href="styles/main.css" /> 
  </head>

  <body>
    <header id="top" class="hero">
      <div class="container hero__inner">
        <img class="hero__photo" src="images/nils.jpg" alt="Portrait of Nils Kuhn" />

        <div class="hero__content">
          <h1 class="hero__title">Nils Kuhn</h1>
          <p class="hero__subtitle">I am an M.S. student in Electrical Engineering at Stanford University, 
            where I work with Jeannette Bohg on dexterous manipulation. Previously, I interned at the European 
            Space Agency under the supervision of Federico Antonello, researching continual learning methods for 
            anomaly detection. I hold a B.Sc. in Mechatronics and a B.Sc. in Engineering and Business Administration 
            from Leibniz University Hannover. There, I completed my thesis under the supervision of Marc Wurz 
            on thin-film insulation, and I worked with Christian Ospelkaus on trapped-ion quantum computing. </p>

          <p class="hero__subtitle">I am supported by a Tuition Fellowship from Stanford University, 
            as well as scholarships from the German Academic Exchange Service (DAAD) and the Friedrich-Ebert-Stiftung. 
            During my undergraduate studies, I received the Jürgen Ulderup Award (B.Sc. Mechatronics) and the 
            Wilhelm Launhardt Award (B.Sc. Engineering and Business Administration), and I was named to the 
            Dean's List in 2023 and 2024 for both programs. </p>

          <p class="hero__contact">
            Feel free to contact me:
            <a class="hero__email" href="mailto:nfkuhn@stanford.edu">nfkuhn@stanford.edu</a>
          </p>

          <div class="hero__links" aria-label="Links">
            <a class="icon-link-1" href="https://github.com/DerKuhno" target="_blank" rel="noopener noreferrer">GitHub</a>
            <a class="icon-link-1" href="https://www.linkedin.com/in/nils-kuhn/" target="_blank" rel="noopener noreferrer">LinkedIn</a>
            <a class="icon-link-1" href="mailto:nfkuhn@stanford.edu">Email</a>
          </div>
        </div>
      </div>
    </header>

    <main class="main">
      <section class="section" aria-labelledby="research-title">
        <div class="container">
          <h2 class="section__title" id="research-title">Research interests</h2>

          <p> My research interests broadly span robot learning, with a focus on 
            vision language action models and diffusion based approaches for tasks involving mobile manipulation, 
            long horizon planning, dexterous manipulation or super human performance.
            Specifically, I am curious about hierarchical approaches and approaches that support continual learning.</p>

          <ul class="interest-grid">
            <li class="interest">
              <img class="interest__icon" src="images/mobile_manipulation.png" alt="" />
              <h3 class="interest__title">Mobile manipulation</h3>
            </li>

            <li class="interest">
              <img class="interest__icon" src="images/dexterous manipulation.png" alt="" />
              <h3 class="interest__title">Dexterous manipulation</h3>
            </li>

            <li class="interest">
              <img class="interest__icon" src="images/robot_learning.png" alt="" />
              <h3 class="interest__title">Continual Learning</h3>
            </li>
          </ul>
        </div>
      </section>

      <section class="section" aria-labelledby="projects-title">
        <div class="container">
          <h2 class="section__title" id="projects-title">Coming soon...</h2>

          <ul class="project-list">
            <li class="project">
              <a class="project__card">
                <img class="project__image" src="images/projects/loading.png" alt="Screenshot of the swarm in movement" />
                <div class="project__content">
                  <h3 class="project__title">Continual Learning ... Anomaly prediction ... Sattelite Telemetry</h3>
                  <p class="project__text"> Work in progress...</p>
                </div>
              </a>
            </li>

          </ul>
        </div>
      </section>

      <section class="section" aria-labelledby="projects-title">
        <div class="container">
          <h2 class="section__title" id="projects-title">Projects</h2>

          <ul class="project-list">
            <li class="project">
              <a class="project__card" href="projects/diffusion.html">
                <img class="project__image" src="images/projects/diffusion.png" alt="Diffusion processes" />
                <div class="project__content">
                  <h3 class="project__title">Continuous-Time Diffusion Policies for Visuomotor Control: <br>
                    A Stochastic Calculus Perspective</h3>
                  <p class="project__text">Reframed diffusion policies as controlled SDEs (VP/VE/CLD) for visuomotor control.
                      Implemented multiple samplers and compared robustness on the PushT benchmark.
                      Found VP-SDE performs best and most consistently (≈0.78-0.80 success).</p>
                </div>
              </a>
            </li>

            <li class="project">
              <a class="project__card" href="https://cs231n.stanford.edu/2025/papers/text_file_840560503-CS_231n_Final_Project.pdf">
                <img class="project__image" src="images/projects/GeoVision.png" alt="Project 3 preview image" />
                <div class="project__content">
                  <h3 class="project__title">GeoVision: Fine-Grained Urban Geolocation in San Francisco via Distribution-Aware Visual Models</h3>
                  <p class="project__text">GeoVision predicts where a street photo was taken within San Francisco using a Vision 
                    Transformer (StreetCLIP) plus custom geolocation heads. A 31x31 grid classifier reaches 66.8% top-1 accuracy, 
                    while a probabilistic Gaussian head achieves ~600m mean localization error and provides uncertainty estimates. 
                    The project includes map-based visualizations and attention rollouts to show what cues the model uses when 
                    localizing images. </p>
                </div>
              </a>
            </li>

            <li class="project">
              <a class="project__card" href="https://cs224r.stanford.edu/projects/pdfs/CS224R_Project-1.pdf">
                <img class="project__image" src="images/projects/mario_frame.png" alt="Project 4 preview image" />
                <div class="project__content">
                  <h3 class="project__title">MARIO: Reinforcement Learning on Image Observations</h3>
                  <p class="project__text">We trained PPO and DQN agents to play Super Mario Bros. directly 
                    from raw pixels (stacked grayscale frames with the full 12-action control space), 
                    achieving 96.32% Level 1-1 completion with PPO using a top-k (k=3) pseudo-greedy 
                    inference strategy and pushing DQN to ~91% with PPO-inspired architecture/preprocessing 
                    changes; we then evaluated transfer from Level 1-1 to Level 1-2 and found generalization 
                    remained challenging under visual/dynamics shift even after retraining.</p>
                </div>
              </a>
            </li>
            
          </ul>
        </div>
      </section>

      <section class="section" aria-labelledby="projects-title">
        <div class="container">
          <h2 class="section__title" id="projects-title">Other projects</h2>

          <ul class="project-list">
            <li class="project">
              <a class="project__card" href="projects/swarm-controller.html">
                <img class="project__image" src="images/projects/drones_moving.png" alt="Screenshot of the swarm in movement" />
                <div class="project__content">
                  <h3 class="project__title">Learning ROS 2: Swarm Controller</h3>
                  <p class="project__text">I built a small ROS 2 drone-show simulation in Gazebo, 
                    where users can spawn any number of drones and command them into a scalable line 
                    or circle formation. A Python interface node uses an action client to send formation 
                    settings to a C++ controller node, which coordinates the drone nodes via
                    publisher/subscriber communication. Live feedback of the progress is send back to the interface. </p>
                </div>
              </a>
            </li>

          </ul>
        </div>
      </section>

    </main>

    <footer class="footer">
      <div class="container">
        <div class="footer__row">
          <a class="footer__top" href="#top">Back to the top</a>
        </div>

        <div class="footer__icons" aria-label="Footer links">
          <a class="icon-link" href="https://github.com/DerKuhno" target="_blank" rel="noopener noreferrer" aria-label="GitHub">
            <!-- GitHub icon -->
            <svg class="icon" viewBox="0 0 24 24" role="img" aria-hidden="true">
              <path d="M12 .5C5.73.5.75 5.64.75 12c0 5.1 3.29 9.43 7.86 10.96.57.11.78-.25.78-.55
              0-.27-.01-1.16-.02-2.1-3.2.71-3.88-1.39-3.88-1.39-.52-1.35-1.28-1.71-1.28-1.71-1.05-.73.08-.71.08-.71
              1.16.08 1.77 1.22 1.77 1.22 1.03 1.81 2.7 1.29 3.36.99.1-.77.4-1.29.73-1.59-2.55-.3-5.23-1.28-5.23-5.7
              0-1.29.45-2.35 1.19-3.18-.12-.3-.52-1.52.11-3.17 0 0 .97-.32 3.18 1.21.92-.26 1.9-.39 2.88-.4
              .98.01 1.96.14 2.88.4 2.2-1.53 3.17-1.21 3.17-1.21.63 1.65.23 2.87.11 3.17.74.83 1.19 1.89 1.19 3.18
              0 4.54-2.69 5.53-5.25 5.83.41.37.78 1.1.78 2.22 0 1.6-.02 2.88-.02 3.27 0 .31.2.67.79.55
              4.57-1.53 7.85-5.86 7.85-10.96C23.25 5.64 18.27.5 12 .5Z"/>
            </svg>
          </a>

          <a class="icon-link" href="https://www.linkedin.com/in/nils-kuhn/" target="_blank" rel="noopener noreferrer" aria-label="LinkedIn">
            <!-- LinkedIn icon -->
            <svg class="icon" viewBox="0 0 24 24" role="img" aria-hidden="true">
              <path d="M22.23 0H1.77C.79 0 0 .77 0 1.72v20.56C0 23.23.79 24 1.77 24h20.46C23.2 24 24 23.23 24 22.28V1.72C24 .77 23.2 0 22.23 0zM7.06 20.45H3.56V9h3.5v11.45zM5.31 7.43a2.03 2.03 0 1 1 0-4.06 2.03 2.03 0 0 1 0 4.06zM20.45 20.45h-3.5v-5.57c0-1.33-.03-3.04-1.85-3.04-1.85 0-2.14 1.45-2.14 2.94v5.67h-3.5V9h3.36v1.56h.05c.47-.88 1.62-1.8 3.33-1.8 3.56 0 4.2 2.34 4.2 5.39v6.3z"/>
            </svg>
          </a>

          <a class="icon-link" href="mailto:nfkuhn@stanford.edu" aria-label="Email">
            <!-- Email icon -->
            <svg class="icon" viewBox="0 0 24 24" role="img" aria-hidden="true">
              <path d="M20 4H4c-1.1 0-2 .9-2 2v12c0 1.1.9 2 2 2h16c1.1 0 2-.9 2-2V6c0-1.1-.9-2-2-2Zm0 4-8 5-8-5V6l8 5 8-5v2Z"/>
            </svg>
          </a>
        </div>

        <p class="footer__meta">&copy; Nils Kuhn &middot; 2026 &middot; nilskuhn.com</p>
      </div>
    </footer>
  </body>
</html>
